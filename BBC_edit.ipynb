{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdonggyu2008/hufs_hackerthon/blob/main/BBC_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#사전세팅\n"
      ],
      "metadata": {
        "id": "yfOIOBwmOPjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBGrW2c2Ef9J",
        "outputId": "5f4b8ab2-3743-4b4d-b579-45b924ec3232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uVbz_C2xYoIX"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLarvQsWExGS",
        "outputId": "872616e0-0f70-400c-e319-3b76a7389135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras.preprocessing) (1.26.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras.preprocessing) (1.16.0)\n",
            "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras.preprocessing\n",
            "Successfully installed keras.preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cj15fY1zEY_a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RZ-xexCXYrjF"
      },
      "outputs": [],
      "source": [
        "# os.environ['WANDB_API_KEY']='513a1f0c050fa7f60a76b5232e904d8df397082e'\n",
        "# os.environ['WANDB_ENTITY']='article classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dGjBBIEqYqgR"
      },
      "outputs": [],
      "source": [
        "# !wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRQWJwY-Gcoi"
      },
      "source": [
        "#감정분석(필요?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZvij9nICb5",
        "outputId": "05059c89-05cc-4d53-e52b-6b0e93180f67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcy4E3ITI-QN",
        "outputId": "ce96e760-d344-4101-964f-05367f0595e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -qq fonts-nanum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "35872_0iH8Ci"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from konlpy.tag import Okt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jPPXl70NEls2"
      },
      "outputs": [],
      "source": [
        "#augmented, 500개로 맞춤\n",
        "#augmented2, 1000개로 맞춤\n",
        "#augmented_combined, 동일 카테고리별로 5개씩 묶고, 합친 갯수가 200개보다 적으면 200개까지 증강\n",
        "#augmented_combined3, 동일 카테고리별로 2개씩 묶고, 합친 갯수가 200개보다 적으면 50개까지 증강\n",
        "#augmented_combined4, 셔플 추가, 동일 카테고리별로 2개씩 묶고, 합친 갯수가 200개보다 적으면 50개까지 증강\n",
        "#augmented_combined5, 셔플 추가, 동일 카테고리별로 2개씩 묶고, 합친 갯수가 200개보다 적으면 50개까지 증강\n",
        "#그리고 지역은 5000개까지 줄임\n",
        "#augmented_combined5, 셔플 추가, 동일 카테고리별로 2개씩 묶고, 합친 갯수가 30개보다 적으면 30개까지 증강\n",
        "df=pd.read_csv('/content/drive/MyDrive/data/dacon_project/data/train_augmented_combined10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rcmBk_3IIRvf"
      },
      "outputs": [],
      "source": [
        "okt=Okt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pWaSQoSaIBjP"
      },
      "outputs": [],
      "source": [
        "def preprocess_korean(text):\n",
        "    # 특수문자 제거 및 소문자 변환\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "    # 형태소 분석 후 명사만 추출\n",
        "    tokens = okt.nouns(text)\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS57fre0KOab"
      },
      "source": [
        "#토크나이징 및 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AKT_6IsRHG61"
      },
      "outputs": [],
      "source": [
        "# 카테고리 목록과 매핑될 레이블 번호를 생성합니다.\n",
        "categories = [\n",
        "    \"지역\", \"경제:부동산\", \"사회:사건_사고\", \"경제:반도체\", \"사회:사회일반\", \"사회:교육_시험\",\n",
        "    \"정치:국회_정당\", \"사회:의료_건강\", \"경제:취업_창업\", \"스포츠:올림픽_아시안게임\",\n",
        "    \"경제:산업_기업\", \"문화:전시_공연\", \"경제:자동차\", \"경제:경제일반\", \"사회:장애인\",\n",
        "    \"스포츠:골프\", \"정치:선거\", \"경제:유통\", \"IT_과학:모바일\", \"사회:여성\",\n",
        "    \"사회:노동_복지\", \"사회:환경\", \"경제:서비스_쇼핑\", \"경제:무역\", \"정치:행정_자치\",\n",
        "    \"국제\", \"문화:방송_연예\", \"스포츠:축구\", \"경제:금융_재테크\", \"정치:청와대\",\n",
        "    \"문화:출판\", \"IT_과학:IT_과학일반\", \"IT_과학:인터넷_SNS\", \"문화:미술_건축\",\n",
        "    \"정치:정치일반\", \"IT_과학:과학\", \"문화:문화일반\", \"문화:학술_문화재\", \"문화:요리_여행\",\n",
        "    \"경제:자원\", \"문화:종교\", \"IT_과학:콘텐츠\", \"사회:미디어\", \"사회:날씨\",\n",
        "    \"스포츠:농구_배구\", \"문화:음악\", \"문화:생활\", \"IT_과학:보안\", \"스포츠:월드컵\",\n",
        "    \"경제:증권_증시\", \"정치:북한\", \"정치:외교\", \"스포츠:스포츠일반\", \"문화:영화\",\n",
        "    \"스포츠:야구\", \"경제:외환\"\n",
        "]\n",
        "\n",
        "# # DataFrame을 랜덤하게 섞습니다.\n",
        "# shuffled = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "# # 각 카테고리에 대해 데이터 샘플링\n",
        "# num_of_categories = 45000\n",
        "# sampled_data = []\n",
        "# for category in categories:\n",
        "#     sampled_data.append(shuffled[shuffled['분류'] == category][:num_of_categories])\n",
        "\n",
        "# # 샘플링된 데이터를 하나의 데이터프레임으로 합칩니다.\n",
        "# concated = pd.concat(sampled_data, ignore_index=True)\n",
        "\n",
        "# # 데이터프레임을 다시 섞습니다.\n",
        "# concated = concated.reindex(np.random.permutation(concated.index))\n",
        "\n",
        "# # LABEL 열 생성 (카테고리별 레이블 부여)\n",
        "# concated['라벨'] = concated['분류'].apply(lambda x: categories.index(x))\n",
        "\n",
        "# # One-hot 인코딩\n",
        "# labels = to_categorical(concated['라벨'], num_classes=len(categories))\n",
        "\n",
        "# #카테고리 열 삭제\n",
        "# if '분류' in concated.columns:\n",
        "#     concated = concated.drop(['분류'], axis=1)\n",
        "\n",
        "# print(concated['라벨'][:10])\n",
        "# print(concated['분류'])\n",
        "# print(labels[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 기사 제목과 키워드를 결합합니다.\n",
        "# df['text'] = df['제목'] + \" \" + df['키워드']\n",
        "\n",
        "# # DataFrame을 랜덤하게 섞습니다.\n",
        "# shuffled = df.reindex(np.random.permutation(df.index))\n",
        "\n",
        "# # 각 카테고리에 대해 데이터 샘플링\n",
        "# num_of_categories = 45000\n",
        "# sampled_data = []\n",
        "# for category in categories:\n",
        "#     sampled_data.append(shuffled[shuffled['분류'] == category][:num_of_categories])\n",
        "\n",
        "# # 샘플링된 데이터를 하나의 데이터프레임으로 합칩니다.\n",
        "# concated = pd.concat(sampled_data, ignore_index=True)\n",
        "\n",
        "# # 데이터프레임을 다시 섞습니다.\n",
        "# concated = concated.reindex(np.random.permutation(concated.index))\n",
        "\n",
        "# # LABEL 열 생성 (카테고리별 레이블 부여)\n",
        "# concated['라벨'] = concated['분류'].apply(lambda x: categories.index(x))\n",
        "\n",
        "# # One-hot 인코딩\n",
        "# labels = to_categorical(concated['라벨'], num_classes=len(categories))\n",
        "\n",
        "# text_lengths = concated['text'].apply(len)\n",
        "# average_length = text_lengths.mean()\n",
        "\n",
        "# # 결합된 텍스트 확인\n",
        "# print(concated[['text', '라벨']].head())"
      ],
      "metadata": {
        "id": "rwV2Qsv1SNaT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 기사 제목과 키워드를 결합합니다.\n",
        "df['text'] = df['제목'] + \" \" + df['키워드']\n",
        "\n",
        "# 카테고리 목록 생성\n",
        "categories = df['분류'].unique().tolist()\n",
        "\n",
        "# DataFrame을 랜덤하게 섞습니다.\n",
        "shuffled = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# 각 카테고리에 대해 데이터 샘플링\n",
        "num_of_categories = 45000\n",
        "sampled_data = []\n",
        "\n",
        "for category in categories:\n",
        "    category_data = shuffled[shuffled['분류'] == category]\n",
        "    sampled_data.append(category_data[:min(len(category_data), num_of_categories)])\n",
        "\n",
        "# 샘플링된 데이터를 하나의 데이터프레임으로 합칩니다.\n",
        "concated = pd.concat(sampled_data, ignore_index=True)\n",
        "\n",
        "# 데이터프레임을 다시 섞습니다.\n",
        "concated = concated.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# LABEL 열 생성 (카테고리별 레이블 부여)\n",
        "concated['라벨'] = concated['분류'].apply(lambda x: categories.index(x))\n",
        "\n",
        "# One-hot 인코딩\n",
        "labels = to_categorical(concated['라벨'], num_classes=len(categories))\n",
        "\n",
        "# 텍스트 길이 계산 및 평균 길이 출력\n",
        "text_lengths = concated['text'].apply(len)\n",
        "average_length = text_lengths.mean()\n",
        "print(f'결합된 텍스트의 평균 길이: {average_length}')\n",
        "\n",
        "# 데이터 크기 확인 (x와 y의 길이가 일치해야 함)\n",
        "print(f'Text data size: {len(concated[\"text\"])}')\n",
        "print(f'Label data size: {len(labels)}')\n",
        "\n",
        "# 결합된 텍스트 및 라벨 확인\n",
        "print(concated[['text', '라벨']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDc52sEwklJt",
        "outputId": "4cc3ec6e-15b8-496a-f3dc-e3ef7f7aad07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결합된 텍스트의 평균 길이: 726.8032059984915\n",
            "Text data size: 1126950\n",
            "Label data size: 1126950\n",
            "                                                text  라벨\n",
            "0  경기농협 팜스테이마을 [창간 도내 특집] 추천 34 경기농협,추천,도내,팜스테이,마...  48\n",
            "1  일본인, 선결제야” 왜 “숙박비 90여만원 격리 창밖으로 뿌려 숙박비,선결제,격리,...   2\n",
            "2  추석맞이 가공식품 우수농산물과 지역 판매 용인특례시 우수농산물,용인,특례시,지역,우...   9\n",
            "3  \"푸바오 안녕\" 포토] 배웅하는 강바오 송바오 [슬라이드 푸바오,안녕,배웅,강바오,...  44\n",
            "4  모집 올해 수출상담회' '언택트 용인시 중진공 참여기업 경기지역본부 중진공,경기,지...  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0pm_DwKEut",
        "outputId": "b0830e5b-6c6c-462f-805d-58d51bac295e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 83625 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "n_most_common_words = 30000\n",
        "max_len = 300\n",
        "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(concated['제목'].values)\n",
        "sequences = tokenizer.texts_to_sequences(concated['제목'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "X = pad_sequences(sequences, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_most_common_words = 20000\n",
        "tokenizer = Tokenizer(num_words=n_most_common_words)\n",
        "\n",
        "# 기사 제목이나 내용을 토큰화할 텍스트로 설정\n",
        "texts = df['text'].values  # '제목' 칼럼을 기준으로 사용\n",
        "\n",
        "# 토큰화 및 텍스트 시퀀스 변환\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# 각 기사의 토큰 개수를 확인\n",
        "token_counts = [len(seq) for seq in sequences]\n",
        "\n",
        "# 토큰 수의 최대값 찾기\n",
        "# max_len = sum(token_counts)/len(token_counts)\n",
        "maxx_len = max(token_counts)\n",
        "print(f\"모든 기사에서 토큰 수의 최대값: {maxx_len}\")\n",
        "\n",
        "# 각 기사의 토큰 수 확인을 위한 데이터프레임 생성\n",
        "token_count_df = pd.DataFrame({\n",
        "    '기사 제목': texts,\n",
        "    '토큰 수': token_counts\n",
        "})\n",
        "\n",
        "# 토큰 수 출력\n",
        "print(token_count_df)\n",
        "print(np.std(token_counts)*0.9)"
      ],
      "metadata": {
        "id": "EaUfS7uVAoDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd034251-6714-4060-a3c0-ed73c5963405"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 기사에서 토큰 수의 최대값: 2370\n",
            "                                                     기사 제목  토큰 수\n",
            "0        용인문화재단, 인문학 콘서트 ‘당신이 모르는 뮤지컬 이야기Ⅳ’ 개최 용인문화재단,인...    85\n",
            "1        용인 농촌테마파크, 7~8월 단체체험객 체험료 지원 용인,농촌,테마파크,단체,체험객...    94\n",
            "2        용인시, 노후주택 에너지 성능 개선 신청 18일까지 연장 용인시,노후,주택,에너지,...    93\n",
            "3        수원 용인 고양시,‘특례시’로 지정 도시경쟁력 증가 기대 수원,용인,고양시,특례시,...   240\n",
            "4        용인시, 스페인 미국 국제명예자문관 위촉 대외홍보 지원 역할 용인시,스페인,미국,국...   102\n",
            "...                                                    ...   ...\n",
            "1126945  로또당첨번호조회, 33억씩'(종합) '1등 당첨번호 당첨지역 7명 공개 932회 로...    93\n",
            "1126946  용인 재계약 하나 '수상골프연습장' 수상골프연습장,재계약,전경,기흥호수,수상,골프,...   244\n",
            "1126947  낸 재정위원회 김진영 KBL, 회부[공식발표] 음주사고 삼성 KBL,음주사고,삼성,...    78\n",
            "1126948  용인시장 [제21회 용인시 경인일보배 인터뷰|이상일 배드민턴] 용인시,경인일보배,배...    99\n",
            "1126949  [부고] 중구청장)씨 빙부상 김길성(서울 김길성,서울,중구청장,빙부상,최원락,별세,...    27\n",
            "\n",
            "[1126950 rows x 2 columns]\n",
            "128.60072945587964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ],
      "metadata": {
        "id": "sJpjg6hhB1tq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReduceLROnPlateau 콜백을 사용해 학습률 감소\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)\n"
      ],
      "metadata": {
        "id": "edXRb51XB4HD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25)"
      ],
      "metadata": {
        "id": "OCEtXLMwlUAM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2Model\n",
        "\n",
        "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(TFGPT2ForSequenceClassification, self).__init__()\n",
        "        self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt=True)\n",
        "        self.classifier = tf.keras.layers.Dense(num_labels,\n",
        "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
        "                                                activation='softmax',\n",
        "                                                name='classifier')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.gpt(input_ids=inputs)\n",
        "        cls_token = outputs[0][:, -1]  # CLS 토큰에 해당하는 마지막 위치의 출력을 사용\n",
        "        prediction = self.classifier(cls_token)\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "MhaUJYi8lX6E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 설정\n",
        "model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\", num_labels=56)  # 분류 클래스 수를 56으로 설정\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()  # 원-핫 인코딩 레이블에 적합한 손실 함수\n"
      ],
      "metadata": {
        "id": "rwLaZfvhlaaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "afa2551cef2b41cf87aa3cebff86155a",
            "ab6d6390990445e987761753f54e7a1a",
            "15194c33cec5467195ce3e48370695ad",
            "8a2687a54e32451ba1d8be40f48d326b",
            "b481e612036042e986cff51361fe2aa4",
            "fb3c539044454c55aeb952b98de339b3",
            "e8b45b6daaad48beaff3c0ec20ccae31",
            "642da6731cbf4167ae86e76357ed821a",
            "347e71d2fa4f4641af95365103760889",
            "34e0830807594adb8445edd376963a27",
            "c46ebff24df34c668d8195704fe8a8e5",
            "d8636f6b245b4cdda0900033bfab5d7c",
            "25cf3791072b450aad09ae44cccfc028",
            "aacacebc10f34095b1a1dabe64770c6b",
            "a0be361bd29f49c5a40db6307f647947",
            "35d1ed92c09543e48ebf43093b0a0fc6",
            "d63cdc51341f4db18eed00b214aacb09",
            "673ce5bbdf5841c398d93a399cef7f7b",
            "141c1c4d8a5d4ca1ac2ad60622d2327b",
            "66bd884a50534d13bb857ff26775c7fa",
            "e7545525fe1a442bb330e3bb3eefdcd9",
            "fc10bdfe870b4f0caa3af6643df7b700"
          ]
        },
        "outputId": "497f5279-2ea3-4431-fc9f-934e48114179"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afa2551cef2b41cf87aa3cebff86155a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8636f6b245b4cdda0900033bfab5d7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.2.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'lm_head.weight', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.1.attn.masked_bias']\n",
            "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/data/dacon_project/model/best_gpt2_model_checkpoint.keras\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n"
      ],
      "metadata": {
        "id": "X1MqMMkF-4OP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n"
      ],
      "metadata": {
        "id": "F4ryY0nh-6L2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "I87HnVYnlbNF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "M8-bO5il--Je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9af049-3ac1-4770-9093-63d16393f797"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "kJ8ShpwJY9Tk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"/content/drive/MyDrive/data/dacon_project/model\"\n"
      ],
      "metadata": {
        "id": "4i_8GcnUZ9sl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import TFGPT2ForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# # 저장된 모델과 토크나이저 불러오기\n",
        "# model = TFGPT2ForSequenceClassification.from_pretrained(checkpoint_dir)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "tNeKOpTjZHZj",
        "outputId": "364c8b42-12fa-40d3-d63c-6e2d4d6a6395"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/content/drive/MyDrive/data/dacon_project/model does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/drive/MyDrive/data/dacon_project/model/tree/main' for available files.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b4627614abc3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 저장된 모델과 토크나이저 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFGPT2ForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             config, model_kwargs = cls.config_class.from_pretrained(\n\u001b[0m\u001b[1;32m   2727\u001b[0m                 \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_token_in_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             logger.warning(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    690\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    374\u001b[0m                     \u001b[0;34mf\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                     \u001b[0;34mf\"'https://huggingface.co/{path_or_repo_id}/tree/{revision}' for available files.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/drive/MyDrive/data/dacon_project/model does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/drive/MyDrive/data/dacon_project/model/tree/main' for available files."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=30,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[checkpoint, early_stopping, reduce_lr])"
      ],
      "metadata": {
        "id": "cXGZ-U4TlcGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0894f070-8ecb-4f87-b64d-15292a3c0a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m   2/6604\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:34:15\u001b[0m 2s/step - accuracy: 0.0195 - loss: 5.8920   "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "GizQhSUzVGJg",
        "outputId": "eacfe533-7536-4896-8480-cb04eff64dbb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Could not locate class 'TFGPT2ForSequenceClassification'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'TFGPT2ForSequenceClassification', 'config': {'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'TFGPT2ForSequenceClassification', 'build_config': {'input_shape': [None, 300]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'module': 'keras.losses', 'class_name': 'CategoricalCrossentropy', 'config': {'name': 'categorical_crossentropy', 'reduction': 'sum_over_batch_size', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1}, 'registered_name': None}, 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-5b9474622dc4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    235\u001b[0m             )\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     cls = _retrieve_class_or_fn(\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0mregistered_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;34mf\"Could not locate {obj_type} '{name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;34m\"Make sure custom classes are decorated with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not locate class 'TFGPT2ForSequenceClassification'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': None, 'class_name': 'TFGPT2ForSequenceClassification', 'config': {'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'TFGPT2ForSequenceClassification', 'build_config': {'input_shape': [None, 300]}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': {'module': 'keras.losses', 'class_name': 'CategoricalCrossentropy', 'config': {'name': 'categorical_crossentropy', 'reduction': 'sum_over_batch_size', 'from_logits': False, 'label_smoothing': 0.0, 'axis': -1}, 'registered_name': None}, 'loss_weights': None, 'metrics': ['accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Best model loss: {loss}, accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "AYcgCQ1KQoVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 학습 결과 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "plt.plot(epochs, history.history['loss'], label='Training loss')\n",
        "plt.plot(epochs, history.history['val_loss'], label='Validation loss')\n",
        "plt.plot(epochs, history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(epochs, history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Model Loss and Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7uDZKzu7jI2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmSYpyJJrnvt"
      },
      "source": [
        "#모델\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwqX8qcBODnN"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Input, Dense, Embedding, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "# from tensorflow.keras.layers import Add\n",
        "# from tensorflow.keras.optimizers import AdamW\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "# from tensorflow.keras.layers import Embedding, LSTM\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# from sklearn.metrics import f1_score\n",
        "# import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSZCnvo9ZV0l"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # 학습 결과 시각화\n",
        "# def plot_training_history(history):\n",
        "#     # 정확도 그래프\n",
        "#     plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "#     plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "#     plt.title('Accuracy')\n",
        "#     plt.xlabel('Epochs')\n",
        "#     plt.ylabel('Accuracy')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "\n",
        "#     # 손실 그래프\n",
        "#     plt.plot(history.history['loss'], label='Train Loss')\n",
        "#     plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "#     plt.title('Loss')\n",
        "#     plt.xlabel('Epochs')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG3czHUXOy9j"
      },
      "outputs": [],
      "source": [
        "# # 기본 설정\n",
        "# n_most_common_words = 70000  # 어휘 수 80,000개로 설정\n",
        "# emb_dim = 128  # 임베딩 벡터의 차원 설정\n",
        "# #max_len = X.shape[1]  # 시퀀스의 길이 (기사 제목의 길이)\n",
        "# num_heads = 8  # Multi-head attention에서 헤드의 개수\n",
        "# ff_dim = 128  # Feed Forward Network의 출력 차원\n",
        "# num_classes = 56  # 최종 클래스의 개수\n",
        "# hidden_units=128\n",
        "\n",
        "# # 최적화된 하이퍼파라미터\n",
        "# learning_rate = 0.00005        # 학습률 (조정 가능)\n",
        "# batch_size = 32             # 배치 크기\n",
        "# epochs = 20                 # 최대 에포크 수\n",
        "# dropout_rate = 0.7           # 드롭아웃 비율\n",
        "# l2_lambda = 0.001             # L2 정규화 값\n",
        "# patience = 7                  # 조기 종료를 위한 patience\n",
        "# min_delta = 0.001             # 조기 종료를 위한 최소 손실 감소량\n",
        "# validation_split = 0.2        # 검증 데이터 비율\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25)"
      ],
      "metadata": {
        "id": "DVtACXMkcV0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def reset_weights(model):\n",
        "#     # 모델의 모든 레이어의 가중치를 초기화\n",
        "#     for layer in model.layers:\n",
        "#         if hasattr(layer, 'kernel_initializer') and layer.kernel_initializer:\n",
        "#             layer.kernel.assign(layer.kernel_initializer(layer.kernel.shape))\n",
        "#         if hasattr(layer, 'bias_initializer') and layer.bias_initializer:\n",
        "#             layer.bias.assign(layer.bias_initializer(layer.bias.shape))"
      ],
      "metadata": {
        "id": "o9qbLR9ieunF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer=AdamW(learning_rate=learning_rate)\n"
      ],
      "metadata": {
        "id": "zzMx6HEOdKa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "\n",
        "\n",
        "# model.add(Embedding(input_dim=n_most_common_words, output_dim=emb_dim))\n",
        "# model.add(LSTM(hidden_units))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n3z7TAO2dN3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCF2rJHTOend"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 커스텀 F1 스코어 메트릭 정의 (텐서 기반)\n",
        "# class F1Score(tf.keras.metrics.Metric):\n",
        "#     def __init__(self, name=\"f1_score\", **kwargs):\n",
        "#         super(F1Score, self).__init__(name=name, **kwargs)\n",
        "#         self.precision = tf.keras.metrics.Precision()\n",
        "#         self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "#         y_pred = tf.argmax(y_pred, axis=1)\n",
        "#         y_true = tf.argmax(y_true, axis=1)\n",
        "#         self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "#         self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "#     def result(self):\n",
        "#         precision = self.precision.result()\n",
        "#         recall = self.recall.result()\n",
        "#         return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "#     def reset_states(self):\n",
        "#         self.precision.reset_states()\n",
        "#         self.recall.reset_states()\n"
      ],
      "metadata": {
        "id": "J-a0yOuyeemE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 콜백 함수 설정\n",
        "# es = EarlyStopping(\n",
        "#     monitor='val_loss',     # 검증 손실을 모니터링\n",
        "#     mode='min',             # 'min' 모드로 설정하여, 손실이 감소하는 것을 추적\n",
        "#     patience=3,             # 손실이 더 이상 개선되지 않는 즉시 학습 중단\n",
        "#     restore_best_weights=True  # 가장 성능이 좋았던 가중치로 복원\n",
        "# )\n",
        "# mc = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n"
      ],
      "metadata": {
        "id": "FhSSGgz0egOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 모델 컴파일 (F1 스코어를 메트릭으로 추가)\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', F1Score()])\n"
      ],
      "metadata": {
        "id": "PjF7KySdehlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 모델 학습\n",
        "# history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "#                     callbacks=[es, mc], validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "CIa5S5k1a8Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_training_history(history)"
      ],
      "metadata": {
        "id": "pickrhNmd7qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시행착오\n"
      ],
      "metadata": {
        "id": "1tsMHGnHeTlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvxNFUFrOQYP"
      },
      "outputs": [],
      "source": [
        "# emb_dim = 128\n",
        "# # 입력층\n",
        "# input_layer = Input(shape=(max_len,))\n",
        "\n",
        "# # Embedding 레이어\n",
        "# embedding_layer = Embedding(input_dim=n_most_common_words, output_dim=emb_dim, input_length=max_len)(input_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDrex_8zOMNV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # 트랜스포머 블록 정의\n",
        "# def transformer_block(x, head_size, num_heads, ff_dim, dropout=0.3):\n",
        "#     # Multi-Head Attention\n",
        "#     attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(x, x)\n",
        "#     attention_output = Dropout(dropout)(attention_output)\n",
        "\n",
        "#     # Add & Normalize\n",
        "#     attention_output = Add()([x, attention_output])\n",
        "#     attention_output = LayerNormalization()(attention_output)\n",
        "\n",
        "#     # Feed Forward Network\n",
        "#     ffn_output = Dense(ff_dim, activation='relu',kernel_regularizer=l2(0.001))(attention_output)\n",
        "#     ffn_output = Dropout(dropout)(ffn_output)\n",
        "#     ffn_output = Dense(emb_dim)(ffn_output)\n",
        "\n",
        "#     # Add & Normalize\n",
        "#     ffn_output = Add()([attention_output, ffn_output])\n",
        "#     ffn_output = LayerNormalization()(ffn_output)\n",
        "\n",
        "#     return ffn_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5KtTLi-OGMK"
      },
      "outputs": [],
      "source": [
        "# # 모델 빌드 함수\n",
        "# def build_model(n_most_common_words, emb_dim, max_len, num_heads, ff_dim, num_classes, dropout_rate):\n",
        "#     # 입력층\n",
        "#     input_layer = Input(shape=(max_len,))\n",
        "\n",
        "#     # Embedding 레이어\n",
        "#     embedding_layer = Embedding(input_dim=n_most_common_words, output_dim=emb_dim, input_length=max_len)(input_layer)\n",
        "\n",
        "#     # 트랜스포머 블록 적용\n",
        "#     x = transformer_block(embedding_layer, emb_dim, num_heads, ff_dim, dropout=dropout_rate)\n",
        "\n",
        "#     # Global Average Pooling\n",
        "#     x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "#     # Dropout (최종 분류 전에 추가)\n",
        "#     x = Dropout(dropout_rate)(x)\n",
        "\n",
        "#     # 분류를 위한 Dense 레이어 (num_classes = 56)\n",
        "#     output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "#     # 모델 정의\n",
        "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh6BvicGOdkU"
      },
      "outputs": [],
      "source": [
        "# model = build_model(n_most_common_words=70000,\n",
        "#                     emb_dim=128,\n",
        "#                     max_len=max_len,\n",
        "#                     num_heads=8,\n",
        "#                     ff_dim=128,\n",
        "#                     num_classes=56,\n",
        "#                     dropout_rate=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TOUlGulMykn"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# import random\n",
        "\n",
        "# # 시드 고정\n",
        "# seed = 42\n",
        "# np.random.seed(seed)\n",
        "# tf.random.set_seed(seed)\n",
        "# random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU-sMBPWgRXj"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfHq_MQHnl73"
      },
      "outputs": [],
      "source": [
        "# early_stopping = EarlyStopping(\n",
        "#     monitor='val_loss',     # 검증 손실을 모니터링\n",
        "#     mode='min',             # 'min' 모드로 설정하여, 손실이 감소하는 것을 추적\n",
        "#     patience=3,             # 손실이 더 이상 개선되지 않는 즉시 학습 중단\n",
        "#     restore_best_weights=True  # 가장 성능이 좋았던 가중치로 복원\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0SZ61DetRNR"
      },
      "outputs": [],
      "source": [
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYiuTCHn5wLW"
      },
      "outputs": [],
      "source": [
        "# epochs=[10,15]\n",
        "# learning_rates=[0.0005,0.0008,0.001]\n",
        "# batch_sizes=[64,128,256]\n",
        "# dropout_rates=[0.3,0.5,0.75]\n",
        "\n",
        "# best_val_loss = np.inf  # 현재 최적의 검증 손실 값\n",
        "# best_val_acc=0\n",
        "# best_hyperparams = {}\n",
        "# best_model_weights = None\n",
        "\n",
        "# for epoch in epochs:\n",
        "#   for learning_rate in learning_rates:\n",
        "#     for batch_size in batch_sizes:\n",
        "#       for dropout_rate in dropout_rates:\n",
        "\n",
        "#         print(f\"Recent epoch: {epoch}\")\n",
        "#         print(f\"Recent learning_rate: {learning_rate}\")\n",
        "#         print(f\"Recent batch_size: {batch_size}\")\n",
        "#         print(f\"Recent dropout_rate: {dropout_rate}\")\n",
        "\n",
        "#         model = build_model(n_most_common_words=n_most_common_words,\n",
        "#                     emb_dim=emb_dim,\n",
        "#                     max_len=max_len,\n",
        "#                     num_heads=num_heads,\n",
        "#                     ff_dim=ff_dim,\n",
        "#                     num_classes=num_classes,\n",
        "#                     dropout_rate=dropout_rate)\n",
        "\n",
        "#         reset_weights(model)\n",
        "\n",
        "#         optimizer=AdamW(learning_rate=learning_rate)\n",
        "#         model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#         checkpoint = ModelCheckpoint(\n",
        "#                     filepath=f'/content/drive/MyDrive/data/dacon_project/model/model_epoch{epoch}_lr{learning_rate}_bs{batch_size}_dr{dropout_rate}.keras',  # 모델을 저장할 경로\n",
        "#                     monitor='val_loss',     # val_loss를 모니터링\n",
        "#                     mode='min',             # val_loss가 최소값일 때 저장\n",
        "#                     save_best_only=True,    # 최적의 val_loss 갱신 시에만 저장\n",
        "#                     verbose=1               # 모델 저장 시 메시지 출력\n",
        "#                 )\n",
        "\n",
        "#         early_stopping = EarlyStopping(\n",
        "#         monitor='val_loss',     # 검증 손실을 모니터링\n",
        "#         mode='min',             # 'min' 모드로 설정하여, 손실이 감소하는 것을 추적\n",
        "#         patience=3,             # 손실이 더 이상 개선되지 않는 즉시 학습 중단\n",
        "#         restore_best_weights=True  # 가장 성능이 좋았던 가중치로 복원\n",
        "#         )\n",
        "\n",
        "#         history = model.fit(\n",
        "#         X_train,\n",
        "#         y_train,\n",
        "#         epochs=epoch,\n",
        "#         batch_size=batch_size,\n",
        "#         validation_split=validation_split,\n",
        "#         callbacks=[early_stopping, checkpoint],\n",
        "#         verbose=1)\n",
        "\n",
        "\n",
        "#         val_loss = min(history.history['val_loss'])\n",
        "#         val_acc = max(history.history['val_accuracy'])\n",
        "#         if (val_loss < best_val_loss and val_acc > best_val_acc) and val_loss < 1:\n",
        "\n",
        "#                     best_val_loss = val_loss\n",
        "#                     best_val_acc = val_acc\n",
        "#                     best_hyperparams['epoch'] = epoch\n",
        "#                     best_hyperparams['learning_rate'] = learning_rate\n",
        "#                     best_hyperparams['batch_size'] = batch_size\n",
        "#                     best_hyperparams['dropout_rate'] = dropout_rate\n",
        "#                     best_model_weights=model.get_weights()\n",
        "\n",
        "#         #plot_training_history(history)\n",
        "\n",
        "# # 최종 결과 출력\n",
        "# model.save('/content/drive/MyDrive/data/dacon_project/model/best_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACYBcwcJMfzd"
      },
      "outputs": [],
      "source": [
        "# model.set_weights(best_model_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB5qmrKGLO1A"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpHZ3Bd-LGGd"
      },
      "outputs": [],
      "source": [
        "# model=load_model('/content/drive/MyDrive/data/dacon_project/model/model_epoch10_lr0.0001_bs64_dr0.3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2bBkDVl3kKu"
      },
      "outputs": [],
      "source": [
        "# print(f\"Best val_loss: {best_val_loss}\")\n",
        "# print(f\"Best val_acc: {best_val_acc}\")\n",
        "# print(f\"Best Hyperparameters: Epoch: {best_hyperparams['epoch']}, \"\n",
        "#       f\"Learning Rate: {best_hyperparams['learning_rate']}, \"\n",
        "#       f\"Batch Size: {best_hyperparams['batch_size']}, \"\n",
        "#       f\"Dropout Rate: {best_hyperparams['dropout_rate']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P298qHAdgIu"
      },
      "outputs": [],
      "source": [
        "# # # 최적화된 하이퍼파라미터\n",
        "# learning_rate = 0.001        # 학습률 (조정 가능)\n",
        "# batch_size = 32             # 배치 크기\n",
        "# epochs = 15                  # 최대 에포크 수\n",
        "# dropout_rate = 0.7           # 드롭아웃 비율\n",
        "# l2_lambda = 0.001             # L2 정규화 값\n",
        "# patience = 5                  # 조기 종료를 위한 patience\n",
        "# min_delta = 0.001             # 조기 종료를 위한 최소 손실 감소량\n",
        "# validation_split = 0.2        # 검증 데이터 비율\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "NhAmhKdR3U1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # SGD 옵티마이저로 변경\n",
        "# optimizer = SGD(learning_rate=learning_rate)  # 필요시 momentum=0.9 추가 가능\n",
        "\n",
        "# # 모델 컴파일\n",
        "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Ou8ETV-B3Wzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sjHEL7d_NO"
      },
      "outputs": [],
      "source": [
        "# optimizer=AdamW(learning_rate=learning_rate)\n",
        "# model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39re5JFVLIYu"
      },
      "outputs": [],
      "source": [
        "# reset_weights(model)\n",
        "# history = model.fit(\n",
        "#     X_train,\n",
        "#     y_train,\n",
        "#     epochs=epochs,\n",
        "#     batch_size=batch_size,\n",
        "#     validation_split=validation_split,\n",
        "#     callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm5kEkgNZNrD"
      },
      "outputs": [],
      "source": [
        "# plot_training_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#저장 및 정확도\n"
      ],
      "metadata": {
        "id": "tBJsFoPIeXQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N7z6VIrYaKH"
      },
      "outputs": [],
      "source": [
        "# 모델 전체를 저장하는 코드 (모델 아키텍처, 가중치, 컴파일 정보 포함)\n",
        "model.save('/content/drive/MyDrive/data/dacon_project/result/bbc_edit_model.keras')  # 모델을 'model.h5' 파일로 저장\n",
        "\n",
        "print(\"모델이 'bbc_edit_model.keras'로 저장되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEHHGtG0PT13"
      },
      "outputs": [],
      "source": [
        "# accr = model.evaluate(X_test,y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accr = model.evaluate(X_test,y_test)\n",
        "# print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "id": "YLB-Ikl7DBcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhPTfE-PfKs"
      },
      "outputs": [],
      "source": [
        "# txt = [\"용인특례시, 가을 신학기 학교 급식 공급업체 위생점검\"]\n",
        "# seq = tokenizer.texts_to_sequences(txt)\n",
        "# padded = pad_sequences(seq, maxlen=max_len)\n",
        "# pred = model.predict(padded)\n",
        "# labels = [\n",
        "#     \"지역\", \"경제:부동산\", \"사회:사건_사고\", \"경제:반도체\", \"사회:사회일반\", \"사회:교육_시험\",\n",
        "#     \"정치:국회_정당\", \"사회:의료_건강\", \"경제:취업_창업\", \"스포츠:올림픽_아시안게임\",\n",
        "#     \"경제:산업_기업\", \"문화:전시_공연\", \"경제:자동차\", \"경제:경제일반\", \"사회:장애인\",\n",
        "#     \"스포츠:골프\", \"정치:선거\", \"경제:유통\", \"IT_과학:모바일\", \"사회:여성\",\n",
        "#     \"사회:노동_복지\", \"사회:환경\", \"경제:서비스_쇼핑\", \"경제:무역\", \"정치:행정_자치\",\n",
        "#     \"국제\", \"문화:방송_연예\", \"스포츠:축구\", \"경제:금융_재테크\", \"정치:청와대\",\n",
        "#     \"문화:출판\", \"IT_과학:IT_과학일반\", \"IT_과학:인터넷_SNS\", \"문화:미술_건축\",\n",
        "#     \"정치:정치일반\", \"IT_과학:과학\", \"문화:문화일반\", \"문화:학술_문화재\", \"문화:요리_여행\",\n",
        "#     \"경제:자원\", \"문화:종교\", \"IT_과학:콘텐츠\", \"사회:미디어\", \"사회:날씨\",\n",
        "#     \"스포츠:농구_배구\", \"문화:음악\", \"문화:생활\", \"IT_과학:보안\", \"스포츠:월드컵\",\n",
        "#     \"경제:증권_증시\", \"정치:북한\", \"정치:외교\", \"스포츠:스포츠일반\", \"문화:영화\",\n",
        "#     \"스포츠:야구\", \"경제:외환\"\n",
        "# ]\n",
        "# # print(pred, labels[np.argmax(pred)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgikRQGtYAYO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. test.csv 파일 로드\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/data/dacon_project/data/test.csv')\n",
        "\n",
        "# 2. 데이터 전처리: 제목을 시퀀스로 변환\n",
        "# 학습 시 사용했던 tokenizer를 사용하여 제목을 시퀀스로 변환\n",
        "sequences_test = tokenizer.texts_to_sequences(test_df['제목'].values)\n",
        "\n",
        "# 3. 시퀀스의 길이를 동일하게 맞추기 (max_len에 맞춰 패딩)\n",
        "X_test = pad_sequences(sequences_test, maxlen=max_len)\n",
        "\n",
        "# 4. 모델을 사용하여 예측\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 5. 예측 결과에서 가장 확률이 높은 클래스를 추출\n",
        "predicted_labels = predictions.argmax(axis=1)\n",
        "predicted_labels[predicted_labels>45]=0\n",
        "\n",
        "predicted_class_names=[categories[label] for label in predicted_labels]\n",
        "\n",
        "# 6. submission 데이터프레임 생성 (id와 예측된 레이블을 저장)\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    '분류': predicted_class_names\n",
        "})\n",
        "\n",
        "# 7. submission.csv 파일로 저장\n",
        "submission_df.to_csv('/content/drive/MyDrive/data/dacon_project/result/submission.csv', index=False)\n",
        "\n",
        "print(\"Submission 파일이 생성되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFcqovMmgtWY"
      },
      "outputs": [],
      "source": [
        "df_test=pd.read_csv('/content/drive/MyDrive/data/dacon_project/data/test.csv')\n",
        "df_result=pd.read_csv('/content/drive/MyDrive/data/dacon_project/result/submission.csv')\n",
        "print(\"Shpe of test Data\",df_test.shape)\n",
        "print(\"Shpe of test Data\",df_result.shape)\n",
        "# df_test.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsmrlMh8k2PB"
      },
      "outputs": [],
      "source": [
        "df_result.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUhmLt9dk4Ih"
      },
      "outputs": [],
      "source": [
        "print(df_result['분류'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wMlcQiKxSqy"
      },
      "outputs": [],
      "source": [
        "print(df_result['분류'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "HmSYpyJJrnvt",
        "1tsMHGnHeTlU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afa2551cef2b41cf87aa3cebff86155a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6d6390990445e987761753f54e7a1a",
              "IPY_MODEL_15194c33cec5467195ce3e48370695ad",
              "IPY_MODEL_8a2687a54e32451ba1d8be40f48d326b"
            ],
            "layout": "IPY_MODEL_b481e612036042e986cff51361fe2aa4"
          }
        },
        "ab6d6390990445e987761753f54e7a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3c539044454c55aeb952b98de339b3",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b45b6daaad48beaff3c0ec20ccae31",
            "value": "config.json: 100%"
          }
        },
        "15194c33cec5467195ce3e48370695ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_642da6731cbf4167ae86e76357ed821a",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_347e71d2fa4f4641af95365103760889",
            "value": 1000
          }
        },
        "8a2687a54e32451ba1d8be40f48d326b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e0830807594adb8445edd376963a27",
            "placeholder": "​",
            "style": "IPY_MODEL_c46ebff24df34c668d8195704fe8a8e5",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 62.2kB/s]"
          }
        },
        "b481e612036042e986cff51361fe2aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3c539044454c55aeb952b98de339b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b45b6daaad48beaff3c0ec20ccae31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "642da6731cbf4167ae86e76357ed821a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347e71d2fa4f4641af95365103760889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34e0830807594adb8445edd376963a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46ebff24df34c668d8195704fe8a8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8636f6b245b4cdda0900033bfab5d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25cf3791072b450aad09ae44cccfc028",
              "IPY_MODEL_aacacebc10f34095b1a1dabe64770c6b",
              "IPY_MODEL_a0be361bd29f49c5a40db6307f647947"
            ],
            "layout": "IPY_MODEL_35d1ed92c09543e48ebf43093b0a0fc6"
          }
        },
        "25cf3791072b450aad09ae44cccfc028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63cdc51341f4db18eed00b214aacb09",
            "placeholder": "​",
            "style": "IPY_MODEL_673ce5bbdf5841c398d93a399cef7f7b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "aacacebc10f34095b1a1dabe64770c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141c1c4d8a5d4ca1ac2ad60622d2327b",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66bd884a50534d13bb857ff26775c7fa",
            "value": 513302779
          }
        },
        "a0be361bd29f49c5a40db6307f647947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7545525fe1a442bb330e3bb3eefdcd9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc10bdfe870b4f0caa3af6643df7b700",
            "value": " 513M/513M [00:02&lt;00:00, 246MB/s]"
          }
        },
        "35d1ed92c09543e48ebf43093b0a0fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63cdc51341f4db18eed00b214aacb09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673ce5bbdf5841c398d93a399cef7f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "141c1c4d8a5d4ca1ac2ad60622d2327b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66bd884a50534d13bb857ff26775c7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7545525fe1a442bb330e3bb3eefdcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc10bdfe870b4f0caa3af6643df7b700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}